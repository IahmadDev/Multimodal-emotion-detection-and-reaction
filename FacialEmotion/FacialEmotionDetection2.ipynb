{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.utils import np_utils\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers import BatchNormalization\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-0\n",
      "\n",
      "Loaded the images of dataset-1\n",
      "\n",
      "Loaded the images of dataset-2\n",
      "\n",
      "Loaded the images of dataset-3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(501, 80, 80, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/Datev Ma/Desktop/JupyterNotebook/CK+48/CK+48/'\n",
    "data_dir_list = os.listdir(data_path) # 0 1 2 3\n",
    "\n",
    "num_epoch=10\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(80,80))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        \n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape\n",
    "\n",
    "\n",
    "# for category in classes:\n",
    "#     path = os.path.join(dataset_path, category)\n",
    "#     imgs_in_category = os.listdir(path)\n",
    "#     print ('Loaded the images of dataset-'+'{}\\n'.format(category))\n",
    "#     for img in imgs_in_category:\n",
    "#         try:\n",
    "#             img_array = cv2.imread(os.path.join(path, img))\n",
    "#             new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "#             training_data.append([new_array, category])\n",
    "#         except Exception as e:\n",
    "#             pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:134]=0 #135\n",
    "labels[135:209]=1 #54  75\n",
    "labels[210:416]=2 #177  207\n",
    "labels[417:500]=3 #75   84\n",
    "\n",
    "names = ['0','1','2','3']\n",
    "\n",
    "def getLabel(id):\n",
    "    return ['anger','fear','happy','sadness'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "x_test=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_shape=(80,80,3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='RMSprop')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 80, 80, 6)         456       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 40, 40, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 40, 40, 16)        2416      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 40, 40, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 20, 20, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 18, 18, 64)        9280      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 9, 9, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               663680    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676,348\n",
      "Trainable params: 676,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_custom = create_model()\n",
    "model_custom.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "scores_loss = []\n",
    "scores_acc = []\n",
    "k_no = 0\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_Train_ = x[train_index]\n",
    "    Y_Train = y[train_index]\n",
    "    X_Test_ = x[test_index]\n",
    "    Y_Test = y[test_index]\n",
    "\n",
    "    #file_path = \"/kaggle/working/weights_best_\"+str(k_no)+\".hdf5\"\n",
    "    #checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=8)\n",
    "\n",
    "    #callbacks_list = [checkpoint, early]\n",
    "\n",
    "    model = create_model()\n",
    "    #hist = model.fit_generator(aug.flow(X_Train_, Y_Train), epochs=EPOCHS,validation_data=(X_Test_, Y_Test), callbacks=callbacks_list, verbose=0)\n",
    "    hist = model.fit(X_Train_, Y_Train, batch_size=batch_size, epochs=EPOCHS, validation_data=(X_Test_, Y_Test), verbose=1)\n",
    "    #model.load_weights(file_path)\n",
    "    result.append(model.predict(X_Test_))\n",
    "    score = model.evaluate(X_Test_,Y_Test, verbose=0)\n",
    "    scores_loss.append(score[0])\n",
    "    scores_acc.append(score[1])\n",
    "    k_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('model_8_50epoch80_CK48dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}